name: "MNISTVariationalAutoencoder"
layer {
  name: "data"
  type: "Data"
  top: "data"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.0039215684
  }
  data_param {
    source: "$CAFFE_PATH/examples/mnist/mnist_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.0039215684
  }
  data_param {
    source: "$CAFFE_PATH/examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "datasplit"
  type: "Slice"
  bottom: "data"
  top: "data_left"
  top: "data_center"
  top: "data_right"
  slice_param{
    axis: 3
    slice_point: 13
    slice_point: 14
  }
}
layer {
  name: "uniform"
  type: "DummyData"
  top: "uniform"
  dummy_data_param {
    shape{
      dim: 100
      dim: 1
      dim: 28
      dim: 1
    }
    data_filler {
      type: "uniform"
      min: 0
      max: 1
    }
  }
}
layer {
  name: "dataconcat"
  type: "Concat"
  bottom: "uniform"
  bottom: "data_center"
  top: "dataconcat"
  concat_param {
    axis: 3
  }
}
layer {
  name: "data_center_binary"
  type: "ArgMax"
  bottom: "dataconcat"
  top: "data_center_binary"
  argmax_param {
    axis: 3
  }
}
layer {
  name: "data_target"
  type: "Concat"
  bottom: "data_left"
  bottom: "data_right"
  concat_param {
    axis: 3
  }
  top: "data_target"
}
layer {
  name: "flatdata_target"
  type: "Flatten"
  bottom: "data_target"
  top: "flatdata_target"
  include {
    phase: TRAIN
  }
}
layer {
  name: "silence_target"
  type: "Silence"
  bottom: "data_target"
  include {
    phase: TEST
  }
}
layer {
  name: "input1"
  type: "InnerProduct"
  bottom: "data_center_binary"
  top: "input1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.1
      sparse: 15
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "input1neuron"
  type: "ReLU"
  bottom: "input1"
  top: "input1neuron"
}
layer {
  name: "input2"
  type: "InnerProduct"
  bottom: "input1neuron"
  top: "input2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "gaussian"
      std: 0.1
      sparse: 15
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "input2neuron"
  type: "ReLU"
  bottom: "input2"
  top: "input2neuron"
}
layer {
  name: "input3"
  type: "InnerProduct"
  bottom: "input2neuron"
  top: "input3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 250
    weight_filler {
      type: "gaussian"
      std: 0.1
      sparse: 15
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "input3neuron"
  type: "ReLU"
  bottom: "input3"
  top: "input3neuron"
}

layer {
  name: "input4"
  type: "InnerProduct"
  bottom: "input3neuron"
  top: "input4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 250
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}


layer {
  name: "encode1"
  type: "InnerProduct"
  bottom: "data_target"
  top: "encode1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.1
      sparse: 15
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  include {
    phase: TRAIN
  }
}
layer {
  name: "encode1neuron"
  type: "ReLU"
  bottom: "encode1"
  top: "encode1neuron"
  include {
    phase: TRAIN
  }
}
layer {
  name: "encode2"
  type: "InnerProduct"
  bottom: "encode1neuron"
  top: "encode2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "gaussian"
      std: 0.1
      sparse: 15
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  include {
    phase: TRAIN
  }
}
layer {
  name: "encode2sum"
  type: "Eltwise"
  bottom: "encode2"
  bottom: "input2"
  top: "encode2sum"
  eltwise_param{
    operation: SUM
  }
  include {
    phase: TRAIN
  }
}
layer {
  name: "encode2neuron"
  type: "ReLU"
  bottom: "encode2sum"
  top: "encode2neuron"
  include {
    phase: TRAIN
  }
}
layer {
  name: "encode3"
  type: "InnerProduct"
  bottom: "encode2neuron"
  top: "encode3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 250
    weight_filler {
      type: "gaussian"
      std: 0.1
      sparse: 15
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  include {
    phase: TRAIN
  }
}
layer {
  name: "encode3neuron"
  type: "ReLU"
  bottom: "encode3"
  top: "encode3neuron"
  include {
    phase: TRAIN
  }
}

# begin VAE z definition
layer {
  name: "mu"
  type: "InnerProduct"
  bottom: "encode3neuron"
  top: "mu"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 30 # num z's
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  include {
    phase: TRAIN
  }
}
# Predict log sd because sd needs to be
# positive, and the exp ensures that it is.
layer {
  name: "logsd"
  type: "InnerProduct"
  bottom: "encode3"
  top: "logsd"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 30 # num z's
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  include {
    phase: TRAIN
  }
}

layer{
  name: "sd"
  type: "Exp"
  bottom: "logsd"
  top: "sd"
  include {
    phase: TRAIN
  }
}
layer{
  name: "var"
  type: "Eltwise"
  bottom: "sd"
  bottom: "sd"
  top: "var"
  eltwise_param{
    operation: PROD
  }
  include {
    phase: TRAIN
  }
}
layer{
  name: "meansq"
  type: "Eltwise"
  bottom: "mu"
  bottom: "mu"
  top: "meansq"
  eltwise_param{
    operation: PROD
  }
  include {
    phase: TRAIN
  }
}
layer{
  name: "kldiv_plus_half"
  type: "Eltwise"
  bottom: "meansq"
  bottom: "var"
  bottom: "logsd"
  top: "kldiv_plus_half"
  eltwise_param{
    operation: SUM
    coeff: 0.5
    coeff: 0.5
    coeff: -1.0
  }
  include {
    phase: TRAIN
  }
}
layer {
  name: "kldiv"
  type: "Power"
  bottom: "kldiv_plus_half"
  top: "kldiv"
  power_param{
    shift: -0.5
  }
  include {
    phase: TRAIN
  }
}
layer{
  name: "klloss"
  type: "Reduction"
  bottom: "kldiv"
  top: "klloss"
  include {
    phase: TRAIN
  }
  loss_weight: 0.01 # 1 over batch_size, because
                    # SigmoidCrossEntropyLoss
                    # normalizes by batch_size but
                    # Reduction does not.
}

layer{
  name: "mu_dummy" # can't call this 'mu' or caffe will try to copy mu's 
                   # parameters into this layer at test time
  type: "DummyData"
  top: "mu"
  dummy_data_param{
    shape {
      dim: 100 # test-time batch_size
      dim: 30 # num z's
    }
    data_filler{
      type: "constant"
      value: 0
    }
  }
  include {
    phase: TEST
  }
}
layer{
  name: "sd"
  type: "DummyData"
  top: "sd"
  dummy_data_param{
    shape {
      dim: 100 # test-time batch_size
      dim: 30 # num z's
    }
    data_filler{
      type: "constant"
      value: 1
    }
  }
  include {
    phase: TEST
  }
}

layer{
  name: "noise"
  type: "DummyData"
  top: "noise"
  dummy_data_param{
    shape {
      dim: 100 # train batch_size
      dim: 30 # num z's
    }
    data_filler{
      type: "gaussian"
      std: 1.
    }
  }
  include {
    phase: TRAIN
  }
}

layer{
  name: "noise"
  type: "DummyData"
  top: "noise"
  dummy_data_param{
    shape {
      dim: 100 # test batch_size
      dim: 30 # num z's
    }
    data_filler{
      type: "gaussian"
      std: 1.
    }
  }
  include {
    phase: TEST
  }
}

layer{
  name: "sdnoise"
  type: "Eltwise"
  bottom: "noise"
  bottom: "sd"
  top: "sdnoise"
  eltwise_param{
    operation: PROD
  }
}
layer{
  name: "sample"
  type: "Eltwise"
  bottom: "mu"
  bottom: "sdnoise"
  top: "sample"
  eltwise_param{
    operation: SUM
  }
}

# end VAE z's definition

layer {
  name: "decode4"
  type: "InnerProduct"
  bottom: "sample"
  top: "decode4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 250
    weight_filler {
      type: "gaussian"
      std: 0.1
      sparse: 15
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "decode4sum"
  type: "Eltwise"
  bottom: "decode4"
  bottom: "input4"
  top: "decode4sum"
}
layer {
  name: "decode4neuron"
  type: "ReLU"
  bottom: "decode4sum"
  top: "decode4neuron"
}
layer {
  name: "decode3"
  type: "InnerProduct"
  bottom: "decode4neuron"
  top: "decode3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "gaussian"
      std: 0.1
      sparse: 15
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "decode3neuron"
  type: "ReLU"
  bottom: "decode3"
  top: "decode3neuron"
}
layer {
  name: "decode2"
  type: "InnerProduct"
  bottom: "decode3neuron"
  top: "decode2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.1
      sparse: 15
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "decode2neuron"
  type: "ReLU"
  bottom: "decode2"
  top: "decode2neuron"
}
layer {
  name: "decode1"
  type: "InnerProduct"
  bottom: "decode2neuron"
  top: "decode1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 756
    weight_filler {
      type: "gaussian"
      std: 0.1
      sparse: 15
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SigmoidCrossEntropyLoss"
  bottom: "decode1"
  bottom: "flatdata_target"
  top: "cross_entropy_loss"
  loss_weight: 1
  include {
    phase: TRAIN
  }
}
layer {
  name: "decode1neuron"
  type: "Sigmoid"
  bottom: "decode1"
  top: "decode1neuron"
}
layer {
  name: "loss"
  type: "EuclideanLoss"
  bottom: "decode1neuron"
  bottom: "flatdata_target"
  top: "l2_error"
  loss_weight: 0
  include {
    phase: TRAIN
  }
}
